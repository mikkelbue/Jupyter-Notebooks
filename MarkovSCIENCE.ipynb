{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MarkovSCIENCE:\n",
    "Generate glorious research article titles about ANY topic!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request                # For opening urls.\n",
    "import xml.etree.ElementTree as ET   # For parsing XML-data.\n",
    "import markovify                     # For building a Markov model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get titles from arXiv.org, according to some search term. urllib.request.urlopen(url).read() returns an XML-file, from which the titles are extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles(search_term, n):\n",
    "    url = 'http://export.arxiv.org/api/query?search_query=all:' + search_term + '&start=0&max_results=' + str(n)\n",
    "    data = urllib.request.urlopen(url).read()\n",
    "    tree = ET.fromstring(data)\n",
    "    titles = []\n",
    "    for i in range(7, 7 + n):\n",
    "        try:\n",
    "            titles.append(tree[i][3].text.replace('\\n', ''))\n",
    "        except IndexError:\n",
    "            pass\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['artificial', 'intelligence', 'machine', 'learning', 'climate', 'change', 'data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through the search terms and add all returned titles to the titles list. This may take a while, depending on the number of titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/7) Reading research articles about: \"artificial\"...\n",
      "(2/7) Reading research articles about: \"intelligence\"...\n",
      "(3/7) Reading research articles about: \"machine\"...\n",
      "(4/7) Reading research articles about: \"learning\"...\n",
      "(5/7) Reading research articles about: \"climate\"...\n",
      "(6/7) Reading research articles about: \"change\"...\n",
      "(7/7) Reading research articles about: \"data\"...\n",
      "\n",
      "Found 7000 articles\n"
     ]
    }
   ],
   "source": [
    "number_of_titles = 1000\n",
    "\n",
    "titles = []\n",
    "\n",
    "for i, topic in enumerate(topics):\n",
    "    print('({}/{}) Reading research articles about: \"{}\"...'.format(i + 1, len(topics), topic))\n",
    "    titles += get_titles(topic, number_of_titles)\n",
    "\n",
    "print('\\nFound {} articles'.format(len(titles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Markov model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = markovify.Text(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some scientific article titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Statistical Mechanical Approach for Agent Based Large Concurrent Intelligent Systems - Part 1 : I X I\n",
      "Optimal Las Vegas City and Lake Mead across the tropical component under global warming\n",
      "Using Sets of Probability Theory for Time Series Databases\n",
      "A robust one-step catalytic machine for binary classification problems: supporting hyperplane machine\n",
      "A Revised Incremental Conductance MPPT Algorithm for Computational Intelligence Algorithms\n",
      "A review of pulsating stars from the Greenhouse World: A Study of Differentially Private Trajectory Data Publication\n",
      "Bayesian active learning for artificial agents\n",
      "Unifying Local and global warming\n",
      "Approximate tight-binding sum rule for the Use of Query Packs\n",
      "M3: Scaling Up Machine Learning for Regression using Path Aggregation\n",
      "Efficient Collection of Definitions of Functions\n",
      "Complexity Analysis and Implementation\n",
      "Proceedings of the gamma-ray flux variations of NGC 1275 based on Internet of Battle Things in Highly Adversarial Environments\n",
      "Data management to support decision-making in health care\n",
      "A Characterization of Uncertainty\n",
      "Why & When Deep Learning for Multivariate Extreme Value Theory for Sigmoid Belief Networks\n",
      "Calibration of Encoder Decoder Models for the high--order heat equation in $\\R^2$\n",
      "Cost-Efficient Data Backup for Data Accountability and Provenance Tracking\n",
      "Unbiased Learning to Teach in Cooperative Multiagent Reinforcement Learning for Improving Big Data Markets\n",
      "Some comments on the sphere\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(text_model.make_sentence())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
